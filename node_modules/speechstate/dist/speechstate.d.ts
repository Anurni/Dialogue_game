import { Settings, Agenda, Hypothesis, RecogniseParameters } from "./types";
interface SSContext {
    settings: Settings;
    audioContext?: AudioContext;
    asrRef?: any;
    ttsRef?: any;
}
/** events sent to the spawned `speechstate` machine **/
type SSEventExtIn = {
    type: "PREPARE";
} | {
    type: "CONTROL";
} | {
    type: "STOP";
} | {
    type: "SPEAK";
    value: Agenda;
} | {
    type: "LISTEN";
    value: RecogniseParameters;
};
/** for sendParent, not type-checked */
type SSEventExtOut = {
    type: "ASR_NOINPUT";
} | {
    type: "ASRTTS_READY";
} | {
    type: "ASR_STARTED";
} | {
    type: "TTS_STARTED";
} | {
    type: "SPEAK_COMPLETE";
} | {
    type: "RECOGNISED";
    value: Hypothesis[];
    nluValue?: any;
};
type SSEventIntIn = {
    type: "TTS_READY";
} | {
    type: "ASR_READY";
} | {
    type: "TTS_ERROR";
};
type SSEvent = SSEventIntIn | SSEventExtIn | SSEventExtOut;
declare const speechstate: import("xstate").StateMachine<SSContext, SSEvent, Record<string, import("xstate").AnyActorRef>, import("xstate").ProvidedActor, import("xstate").ParameterizedObject, import("xstate").ParameterizedObject, string, import("xstate").StateValue, string, Settings, {}, import("xstate").ResolveTypegenMeta<import("xstate").TypegenDisabled, SSEvent, import("xstate").ProvidedActor, import("xstate").ParameterizedObject, import("xstate").ParameterizedObject, string, string>>;
export { speechstate };
//# sourceMappingURL=speechstate.d.ts.map